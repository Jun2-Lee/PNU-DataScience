# Clustering
---
## What is Clustering?
- Clustering의 예
  - 백만장자 거주지 Data ==> 베버리 힐스나 맨해튼에 군집
  - 유권자 데이터 ==> 은퇴자, 젊은 백수 등으로 군집
- 군집화에는 정답이 없다.
  - 대학원생을 젊은 백수와 같이 묶을 수도 있다.
- 왜 군집화를 하는가?
  - 유권자를 예시로는, 전체 유권자 집단을 몇 개의 그룹으로 나눠 각 집단에 특성화된 선거전략을 세울 수 있다.
  - Labeling은 너무 비싼 작업이다.

- 지도학습(Supervised Learning)
  - 학습 데이터에 예측 목표가 되는 속성이 포함 된 경우 (Label이 주어진 경우)
  - ex) 분류, 회귀분석
- 비지도학습(Unsupervised Learning)
  - 학습 데이터에 예측 목표값이 주어지지 않는다. (Label이 주어지지 않는다.)
  - 데이터에 바로 드러나지 않는 숨은 구조를 찾는 기술이다. (ex) 군집화, 차원축소)
    - 군집화: 데이터 항목의 유사도를 기반으로 비슷한 항목들을 묶어 그룹을 찾는 기법이다.
- 군집 분석(Cluster Analysis)
  - Data를 Subsets로 분리하는 과정이다.
  - 각 Subset을 Cluster이라고 하며, Cluster간에는 유사성이 없어야 한다.
  - Clustering Algorithm에 의해서 구현된다.

## Clustering
- Basic Idea : 유사한 객체들끼리 그룹화 시켜야 한다          

<img src="https://user-images.githubusercontent.com/80378041/162123214-94ac5ff4-f448-4035-8dcb-ddc1dd192953.png" width="50%" height="50%" />

### Similarity Measure
- Distance Based : Data들이 떨어진 거리에 따라 묶는다.
  - Spherical Cluster을 만드는 경향이 있다.
  - ex) Euclidean, Road Network, Vector
    - Euclidean Distance : 두 점 사이를 잇는 직선 거리를 말한다.
    - Manhattan Distance : 두 점 사이의 x축거리 + y축거리가 된다.
    - Distance Measure은 아래와 같은 특성을 가져야 한다.
      - Symmetric : D(A, B) = D(B, A)
      - Positivity, Self-similarity : D(A, B) >= 0 | D(A, B) = 0 iff A = B
      - Triangular Inequality : D(A, B) + D(B, C) >= D(A, C)
- Connectivity Based : Density를 고려해서 Clustering한다.
  - 임의의 모양을 갖는 Cluster을 형성한다.
  - ex) Density, Contiguity
